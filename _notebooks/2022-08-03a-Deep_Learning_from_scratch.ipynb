{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "1e2897b1-f2cd-46f2-a257-96f6ff211331",
   "metadata": {},
   "source": [
    "# Deep Learning from scratch with pytorch (1/N)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "1bd68c0a-1847-4781-9015-1cf4873c3839",
   "metadata": {},
   "outputs": [],
   "source": [
    "from fastai.vision.all import *"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "743162ae-3a40-475c-b0fd-d7e6b69370d7",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#3) [Path('train'),Path('labels.csv'),Path('valid')]"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "path = untar_data(URLs.MNIST_SAMPLE)\n",
    "Path.BASE_PATH = path\n",
    "path.ls()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "cc277f08-0384-4d7a-8a1e-c55bb89b95a8",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(#6131) [Path('train/3/55705.png'),Path('train/3/32379.png'),Path('train/3/36132.png'),Path('train/3/50201.png'),Path('train/3/39704.png'),Path('train/3/8475.png'),Path('train/3/5139.png'),Path('train/3/32610.png'),Path('train/3/7784.png'),Path('train/3/45704.png')...]"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "images = (path/'train'/'3').ls()\n",
    "images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "ee96ac82-002b-4cd2-9c0e-fde8ba6d6bd1",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAABwAAAAcCAAAAABXZoBIAAABDElEQVR4nGNgGFigXvvoCEN4lqABVskn///+/Pvv1+8PlhABJiRJL5b/jKyMDCzMfJmYOhUf/IOCH7YMDAwMDCxIks8XSjMwGJ+1V2Zg1T2M1VWBhZ///fthia7Tk5eBQS5FmpuBgeGaKLqeGzAb/70TQZOS2f0dJvcS5lG4V34fZYcxBVLQDTU+B9H25fW/tcZQMUa4rL1pGMOex/e+6E5jWBuK1SMMDJy7/v3PwCFnsevfv7fKqGIKzAwMDAwMUg5P//37dxkmCrXz88afDAw3T60QY2Bg+OB0ASoJCSF39iiY6r8zrv5ANdXqMywAvjZhOMPc6SVE7p4iNlca17z79+/f3XgcnqAfAADGinvcDaX56wAAAABJRU5ErkJggg==\n",
      "text/plain": [
       "<PIL.PngImagePlugin.PngImageFile image mode=L size=28x28>"
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Image.open(images[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "3ecea0ba-1876-4f5d-9321-9e55318ad549",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(torch.Size([12396, 784]),\n",
       " torch.Size([12396]),\n",
       " torch.Size([2038, 784]),\n",
       " torch.Size([2038]))"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "a = torch.stack([tensor(Image.open(o)) for o in (path/'train'/'3').ls()]).reshape(-1, 28*28)/255.\n",
    "b = torch.stack([tensor(Image.open(o)) for o in (path/'train'/'7').ls()]).reshape(-1, 28*28)/255.\n",
    "X = torch.cat([a, b])\n",
    "y = tensor([1]*len(a) + [0]*len(b))\n",
    "\n",
    "a = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'3').ls()]).reshape(-1, 28*28)/255.\n",
    "b = torch.stack([tensor(Image.open(o)) for o in (path/'valid'/'7').ls()]).reshape(-1, 28*28)/255.\n",
    "X_valid = torch.cat([a, b])\n",
    "y_valid = tensor([1]*len(a) + [0]*len(b))\n",
    "\n",
    "X.shape, y.shape, X_valid.shape, y_valid.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "4938e445-4d13-4b7d-8613-9885b3ebdc16",
   "metadata": {},
   "outputs": [],
   "source": [
    "ds = list(zip(X, y))\n",
    "dl = DataLoader(ds, batch_size=256, shuffle=True)\n",
    "\n",
    "ds_valid = list(zip(X_valid, y_valid))\n",
    "dl_valid = DataLoader(ds_valid, batch_size=256)\n",
    "\n",
    "dls = DataLoaders(dl, dl_valid)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "1daeb37a-b55a-4649-94ba-f20289651c81",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(tensor([[-0.4108],\n",
       "         [ 0.9965],\n",
       "         [ 0.5047]], grad_fn=<SliceBackward0>),\n",
       " tensor([-0.0758], requires_grad=True))"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "weights = torch.randn((28*28, 1)).requires_grad_()\n",
    "bias = torch.randn(1).requires_grad_()\n",
    "\n",
    "weights[:3], bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "bbb30a85-529b-423a-9335-3dbc59859ec0",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "tensor([[ 5.9452],\n",
       "        [10.0471],\n",
       "        [-8.5174],\n",
       "        [ 7.4015],\n",
       "        [ 3.0735]], grad_fn=<AddBackward0>)"
      ]
     },
     "execution_count": 8,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "X[:5]@weights + bias"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 79,
   "id": "47ba5e9e-ee64-4c81-b6c8-cb1a6643fe08",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.429675817489624 tensor(-0.0002) tensor([-0.0027])\n",
      "0.4291311502456665 tensor(-0.0002) tensor([-0.0027])\n",
      "0.42858171463012695 tensor(-0.0002) tensor([-0.0027])\n"
     ]
    }
   ],
   "source": [
    "W = torch.randn((28*28, 1)).requires_grad_()\n",
    "b = torch.randn(1).requires_grad_()\n",
    "lr = 1.\n",
    "X, t = first(dl)\n",
    "\n",
    "def doit():\n",
    "    y = (lambda x: 1/(1+torch.exp(-x)))(X@W + b)\n",
    "    loss = ((t-y)**2).mean()\n",
    "    loss.backward()\n",
    "    print(loss.item(), W.grad.mean(), b.grad)\n",
    "    for p in W, b:\n",
    "        p.data -= lr*p.grad\n",
    "        p.grad.zero_()\n",
    "        \n",
    "      \n",
    "for _ in range(3):    \n",
    "    doit()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 97,
   "id": "71d57df6-b7bc-4bd9-88d7-27d27947fdb0",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 0.42189547419548035 tensor(0.5064)\n",
      "1 0.43536025285720825 tensor(0.5000)\n",
      "2 0.40831637382507324 tensor(0.4987)\n",
      "3 0.4077708125114441 tensor(0.5011)\n",
      "4 0.4055875837802887 tensor(0.5067)\n",
      "5 0.40033259987831116 tensor(0.5110)\n",
      "6 0.39839795231819153 tensor(0.5065)\n",
      "7 0.38762959837913513 tensor(0.5020)\n",
      "8 0.36699414253234863 tensor(0.5065)\n",
      "9 0.39512205123901367 tensor(0.5059)\n",
      "10 0.3689902424812317 tensor(0.5048)\n",
      "11 0.34809964895248413 tensor(0.5012)\n",
      "12 0.34387949109077454 tensor(0.5050)\n",
      "13 0.3494081497192383 tensor(0.5050)\n",
      "14 0.3504391312599182 tensor(0.4992)\n",
      "15 0.333186537027359 tensor(0.5017)\n",
      "16 0.32519006729125977 tensor(0.5150)\n",
      "17 0.31659629940986633 tensor(0.5301)\n",
      "18 0.3194851875305176 tensor(0.5057)\n",
      "19 0.31758102774620056 tensor(0.5000)\n",
      "20 0.3440946042537689 tensor(0.5864)\n",
      "21 0.36963266134262085 tensor(0.5365)\n",
      "22 0.30330464243888855 tensor(0.5538)\n",
      "23 0.33537527918815613 tensor(0.4992)\n",
      "24 0.3367502987384796 tensor(0.5366)\n",
      "25 0.3061891496181488 tensor(0.4945)\n",
      "26 0.3117249011993408 tensor(0.5044)\n",
      "27 0.39691346883773804 tensor(0.5499)\n",
      "28 0.3109123110771179 tensor(0.5000)\n",
      "29 0.338569700717926 tensor(0.4946)\n"
     ]
    }
   ],
   "source": [
    "W = torch.randn((28*28, 1)).requires_grad_()\n",
    "b = torch.randn(1).requires_grad_()\n",
    "lr = 1.\n",
    "\n",
    "def accuracy():\n",
    "    y = (lambda x: 1/(1+torch.exp(-x)))(X_valid@W + b)\n",
    "    return ((y > 0.5)==t).float().mean()\n",
    "\n",
    "for epoch in range(30):\n",
    "    for X, t in dl:\n",
    "        y = (lambda x: 1/(1+torch.exp(-x)))(X@W + b)\n",
    "        loss = ((t-y)**2).mean()\n",
    "        loss.backward()\n",
    "        for p in W, b:\n",
    "            p.data -= lr*p.grad\n",
    "            p.grad.zero_()\n",
    "    print(epoch, loss.item(), accuracy())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "62fc1c96-9103-4fe1-a917-b29b629a1b43",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 (ipykernel)",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.13"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
